{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manga Colorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black&White manga/comic colorization, based on pix2pix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequests: Python 3, GPU # This notebook was tested in datahub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ml-art-project4'...\n",
      "remote: Enumerating objects: 274, done.\u001b[K\n",
      "remote: Counting objects: 100% (274/274), done.\u001b[K\n",
      "remote: Compressing objects: 100% (262/262), done.\u001b[K\n",
      "remote: Total 274 (delta 10), reused 268 (delta 7), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (274/274), 37.50 MiB | 33.83 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n",
      "Checking out files: 100% (243/243), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/glh3025/ml-art-project4.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datasets/home/home-03/75/075/lgong/ml-art-project4\n"
     ]
    }
   ],
   "source": [
    "cd ml-art-project4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.0.1.post2)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.2.1)\n",
      "Requirement already satisfied: dominate>=2.3.1 in /datasets/home/home-03/75/075/lgong/.local/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (2.3.5)\n",
      "Requirement already satisfied: visdom>=0.1.8.3 in /datasets/home/home-03/75/075/lgong/.local/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.1.8.8)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (1.15.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (5.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (1.12.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.12.4)\n",
      "Requirement already satisfied: tornado in /opt/conda/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (5.1.1)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (17.1.2)\n",
      "Requirement already satisfied: torchfile in /datasets/home/home-03/75/075/lgong/.local/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (0.1.0)\n",
      "Requirement already satisfied: websocket-client in /datasets/home/home-03/75/075/lgong/.local/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (0.56.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-30 23:08:41--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
      "Resolving web.ucsd.edu (web.ucsd.edu)... 132.239.1.231, 132.239.1.230\n",
      "Connecting to web.ucsd.edu (web.ucsd.edu)|132.239.1.231|:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 16648024 (16M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
      "\n",
      "ngrok-stable-linux- 100%[===================>]  15.88M  13.8MB/s    in 1.1s    \n",
      "\n",
      "2019-05-30 23:08:42 (13.8 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [16648024/16648024]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ngrok-stable-linux-amd64.zip\n",
      "  inflating: ngrok                   \n"
     ]
    }
   ],
   "source": [
    "! unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let Visdom run background, 8097 is the default output port of pix2pix model.\n",
    "get_ipython().system_raw('python3 -m visdom.server -port 8097 >> visdomlog.txt 2>&1 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 8097 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://af7e1d8d.ngrok.io\r\n"
     ]
    }
   ],
   "source": [
    "# Click the link below to access Visdom.\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split = val, use 28/28 images\n",
      "split = val, number of images = 28\n",
      "split = test, use 8/8 images\n",
      "split = test, number of images = 8\n",
      "split = train, use 141/141 images\n",
      "split = train, number of images = 141\n"
     ]
    }
   ],
   "source": [
    "# Make B&W images from colored ones to save some time\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "data_dir_A = \"datasets/onepiece/A/\"\n",
    "data_dir_B = \"datasets/onepiece/B/\"\n",
    "data_dir_AB = \"datasets/onepiece_AB/\"\n",
    "\n",
    "splits = os.listdir(data_dir_A)\n",
    "\n",
    "for sp in splits:\n",
    "    img_fold_A = os.path.join(data_dir_A, sp)\n",
    "    img_fold_B = os.path.join(data_dir_B, sp)\n",
    "    if not os.path.isdir(img_fold_B):\n",
    "        os.makedirs(img_fold_B)\n",
    "    img_list = os.listdir(img_fold_A)\n",
    "    num_imgs = len(img_list)\n",
    "    print('split = %s, use %d/%d images' % (sp, num_imgs, len(img_list)))\n",
    "    img_fold_AB = os.path.join(data_dir_AB, sp)\n",
    "    if not os.path.isdir(img_fold_AB):\n",
    "        os.makedirs(img_fold_AB)\n",
    "    print('split = %s, number of images = %d' % (sp, num_imgs))\n",
    "    for n in range(num_imgs):\n",
    "        name_A = img_list[n]\n",
    "        path_A = os.path.join(img_fold_A, name_A)\n",
    "        name_B = name_A\n",
    "        path_B = os.path.join(img_fold_B, name_B)\n",
    "        \n",
    "        if os.path.isfile(path_A):# and os.path.isfile(path_B):\n",
    "            name_AB = name_A\n",
    "            path_AB = os.path.join(img_fold_AB, name_AB)\n",
    "            im_A = cv2.imread(path_A, 1) # python2: cv2.CV_LOAD_IMAGE_COLOR; python3: cv2.IMREAD_COLOR\n",
    "#             im_B = cv2.imread(path_B, 1) # python2: cv2.CV_LOAD_IMAGE_COLOR; python3: cv2.IMREAD_COLOR\n",
    "            im_B = cv2.cvtColor(im_A, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imwrite(path_B, im_B)\n",
    "#             im_AB = np.concatenate([im_A, im_B], 1)\n",
    "#             cv2.imwrite(path_AB, im_AB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: w3m: not found\r\n"
     ]
    }
   ],
   "source": [
    "# If use my pretrained model, download from\n",
    "https://drive.google.com/file/d/1BcPpAf7FpQ9hO6LiDeYd086UQ3cybden/view?usp=sharing\n",
    "# and set path ./checkpoints/color_pix2pix/latest_net_G.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 512                           \t[default: 256]\n",
      "                 dataroot: ./datasets/onepiece/A/        \t[default: None]\n",
      "             dataset_mode: colorization                  \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 568                           \t[default: 286]\n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: colorization                  \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: color_pix2pix                 \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_512                      \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 2                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [ColorizationDataset] was created\n",
      "The number of training images = 177\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [ColorizationModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 66.995 M\n",
      "[Network D] Total number of parameters : 2.766 M\n",
      "-----------------------------------------------\n",
      "WARNING:root:Setting up a new session...\n",
      "create web directory ./checkpoints/color_pix2pix/web...\n",
      "(epoch: 1, iters: 100, time: 0.259, data: 0.923) G_GAN: 1.356 G_L1: 8.928 D_real: 0.764 D_fake: 0.394 \n",
      "End of epoch 1 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 23, time: 0.268, data: 0.001) G_GAN: 1.989 G_L1: 6.721 D_real: 0.173 D_fake: 0.201 \n",
      "(epoch: 2, iters: 123, time: 0.254, data: 0.004) G_GAN: 1.507 G_L1: 11.347 D_real: 0.464 D_fake: 0.429 \n",
      "End of epoch 2 / 200 \t Time Taken: 39 sec\n",
      "learning rate = 0.0002000\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 1 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 3, iters: 46, time: 1.969, data: 0.001) G_GAN: 1.649 G_L1: 6.898 D_real: 0.287 D_fake: 0.464 \n",
      "(epoch: 3, iters: 146, time: 0.270, data: 0.001) G_GAN: 1.509 G_L1: 6.306 D_real: 0.352 D_fake: 0.305 \n",
      "End of epoch 3 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 69, time: 0.265, data: 0.001) G_GAN: 1.253 G_L1: 6.059 D_real: 0.510 D_fake: 0.953 \n",
      "(epoch: 4, iters: 169, time: 0.196, data: 0.003) G_GAN: 0.947 G_L1: 6.058 D_real: 0.804 D_fake: 0.585 \n",
      "End of epoch 4 / 200 \t Time Taken: 39 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 92, time: 2.087, data: 0.001) G_GAN: 2.042 G_L1: 7.112 D_real: 0.152 D_fake: 0.200 \n",
      "saving the model at the end of epoch 5, iters 885\n",
      "End of epoch 5 / 200 \t Time Taken: 43 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 15, time: 0.277, data: 0.010) G_GAN: 0.903 G_L1: 6.613 D_real: 0.639 D_fake: 0.441 \n",
      "(epoch: 6, iters: 115, time: 0.270, data: 0.001) G_GAN: 2.314 G_L1: 6.444 D_real: 0.176 D_fake: 0.303 \n",
      "End of epoch 6 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 38, time: 0.191, data: 0.004) G_GAN: 1.304 G_L1: 12.131 D_real: 0.057 D_fake: 0.472 \n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 4 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 7, iters: 138, time: 1.834, data: 0.008) G_GAN: 0.701 G_L1: 5.704 D_real: 1.004 D_fake: 0.786 \n",
      "End of epoch 7 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 61, time: 0.270, data: 0.004) G_GAN: 1.011 G_L1: 9.289 D_real: 0.300 D_fake: 0.802 \n",
      "(epoch: 8, iters: 161, time: 0.269, data: 0.087) G_GAN: 1.137 G_L1: 5.043 D_real: 0.582 D_fake: 0.552 \n",
      "End of epoch 8 / 200 \t Time Taken: 39 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 84, time: 0.263, data: 0.001) G_GAN: 1.027 G_L1: 6.764 D_real: 0.139 D_fake: 0.726 \n",
      "End of epoch 9 / 200 \t Time Taken: 39 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 7, time: 2.186, data: 0.001) G_GAN: 1.731 G_L1: 5.630 D_real: 0.593 D_fake: 0.372 \n",
      "(epoch: 10, iters: 107, time: 0.268, data: 0.003) G_GAN: 0.912 G_L1: 7.237 D_real: 0.748 D_fake: 0.669 \n",
      "saving the model at the end of epoch 10, iters 1770\n",
      "End of epoch 10 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 30, time: 0.265, data: 0.114) G_GAN: 1.329 G_L1: 8.160 D_real: 0.319 D_fake: 0.395 \n",
      "(epoch: 11, iters: 130, time: 0.274, data: 0.001) G_GAN: 1.281 G_L1: 8.789 D_real: 1.414 D_fake: 0.346 \n",
      "End of epoch 11 / 200 \t Time Taken: 39 sec\n",
      "learning rate = 0.0002000\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 39 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 12, iters: 53, time: 2.049, data: 0.001) G_GAN: 1.694 G_L1: 7.102 D_real: 2.170 D_fake: 0.366 \n",
      "(epoch: 12, iters: 153, time: 0.271, data: 0.001) G_GAN: 1.201 G_L1: 5.128 D_real: 0.416 D_fake: 0.591 \n",
      "End of epoch 12 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 76, time: 0.273, data: 0.001) G_GAN: 1.595 G_L1: 13.226 D_real: 0.127 D_fake: 0.252 \n",
      "(epoch: 13, iters: 176, time: 0.174, data: 0.006) G_GAN: 1.429 G_L1: 6.739 D_real: 0.693 D_fake: 0.551 \n",
      "End of epoch 13 / 200 \t Time Taken: 39 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 99, time: 2.208, data: 0.005) G_GAN: 1.435 G_L1: 8.407 D_real: 0.335 D_fake: 0.461 \n",
      "End of epoch 14 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 22, time: 0.267, data: 0.004) G_GAN: 1.075 G_L1: 8.462 D_real: 0.407 D_fake: 1.370 \n",
      "(epoch: 15, iters: 122, time: 0.272, data: 0.001) G_GAN: 1.029 G_L1: 8.709 D_real: 0.192 D_fake: 0.925 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model at the end of epoch 15, iters 2655\n",
      "End of epoch 15 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 45, time: 0.268, data: 0.001) G_GAN: 1.204 G_L1: 7.355 D_real: 0.720 D_fake: 0.603 \n",
      "(epoch: 16, iters: 145, time: 1.730, data: 0.079) G_GAN: 1.613 G_L1: 5.572 D_real: 0.329 D_fake: 0.310 \n",
      "End of epoch 16 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 68, time: 0.193, data: 0.001) G_GAN: 1.202 G_L1: 6.875 D_real: 0.391 D_fake: 0.506 \n",
      "(epoch: 17, iters: 168, time: 0.270, data: 0.001) G_GAN: 0.924 G_L1: 4.429 D_real: 0.572 D_fake: 0.469 \n",
      "End of epoch 17 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 91, time: 0.273, data: 0.102) G_GAN: 1.390 G_L1: 7.051 D_real: 1.207 D_fake: 0.188 \n",
      "End of epoch 18 / 200 \t Time Taken: 39 sec\n",
      "learning rate = 0.0002000\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 312 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 19, iters: 14, time: 2.191, data: 0.001) G_GAN: 0.651 G_L1: 5.249 D_real: 1.723 D_fake: 0.489 \n",
      "(epoch: 19, iters: 114, time: 0.197, data: 0.004) G_GAN: 1.681 G_L1: 5.852 D_real: 0.072 D_fake: 0.485 \n",
      "End of epoch 19 / 200 \t Time Taken: 41 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 37, time: 0.268, data: 0.001) G_GAN: 1.010 G_L1: 4.783 D_real: 0.605 D_fake: 0.700 \n",
      "(epoch: 20, iters: 137, time: 0.196, data: 0.001) G_GAN: 0.606 G_L1: 7.134 D_real: 0.128 D_fake: 1.521 \n",
      "saving the model at the end of epoch 20, iters 3540\n",
      "End of epoch 20 / 200 \t Time Taken: 42 sec\n",
      "learning rate = 0.0002000\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 25 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 21, iters: 60, time: 2.050, data: 0.001) G_GAN: 1.337 G_L1: 6.694 D_real: 0.368 D_fake: 0.311 \n",
      "(epoch: 21, iters: 160, time: 0.195, data: 0.001) G_GAN: 1.376 G_L1: 6.284 D_real: 1.164 D_fake: 0.375 \n",
      "End of epoch 21 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 83, time: 0.272, data: 0.001) G_GAN: 1.813 G_L1: 6.770 D_real: 0.386 D_fake: 0.195 \n",
      "End of epoch 22 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 6, time: 0.197, data: 0.001) G_GAN: 1.216 G_L1: 3.667 D_real: 1.312 D_fake: 0.339 \n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 9 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 23, iters: 106, time: 2.109, data: 0.001) G_GAN: 1.765 G_L1: 8.450 D_real: 0.239 D_fake: 0.314 \n",
      "End of epoch 23 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 29, time: 0.269, data: 0.002) G_GAN: 2.283 G_L1: 6.092 D_real: 0.181 D_fake: 0.147 \n",
      "(epoch: 24, iters: 129, time: 0.270, data: 0.285) G_GAN: 1.285 G_L1: 5.715 D_real: 0.204 D_fake: 0.561 \n",
      "End of epoch 24 / 200 \t Time Taken: 40 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 52, time: 0.270, data: 0.026) G_GAN: 1.003 G_L1: 7.764 D_real: 0.851 D_fake: 0.444 \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 51, in <module>\n",
      "    model.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
      "  File \"/datasets/home/home-03/75/075/lgong/ml-art-project4/models/pix2pix_model.py\", line 126, in optimize_parameters\n",
      "    self.backward_G()                   # calculate graidents for G\n",
      "  File \"/datasets/home/home-03/75/075/lgong/ml-art-project4/models/pix2pix_model.py\", line 111, in backward_G\n",
      "    self.loss_G_L1 = self.criterionL1(self.fake_B, self.real_B) * self.opt.lambda_L1\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 489, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py\", line 93, in forward\n",
      "    return F.l1_loss(input, target, reduction=self.reduction)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\", line 2135, in l1_loss\n",
      "    ret = torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Train model using ~150 onepiece pages. More pages will be better.\n",
    "# modified generator model to Unet512 to get higher resolution image.\n",
    "# By default will train 200 epochs, but ~20 epochs is enough for me.\n",
    "! python train.py --dataroot ./datasets/onepiece/A/ --name color_pix2pix --model colorization --netG unet_512 --load_size 568 --crop_size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 512                           \t[default: 256]\n",
      "                 dataroot: ./datasets/onepiece/A/        \t[default: None]\n",
      "             dataset_mode: colorization                  \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 512                           \t[default: 256]\n",
      "         max_dataset_size: inf                           \n",
      "                    model: colorization                  \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: color_pix2pix                 \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_512                      \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                    ntest: inf                           \n",
      "                 num_test: 8                             \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 2                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [ColorizationDataset] was created\n",
      "initialize network with normal\n",
      "model [ColorizationModel] was created\n",
      "loading the model from ./checkpoints/color_pix2pix/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 66.995 M\n",
      "-----------------------------------------------\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 6 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "processing (0000)-th image... ['./datasets/onepiece/A/test/0001-011.png.jpeg']\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 22 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 19 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 34 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 51 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 56 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "processing (0005)-th image... ['./datasets/onepiece/A/test/0005-011.png.jpeg']\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 16 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 29 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    }
   ],
   "source": [
    "# Generate colored pages from B&W testset.\n",
    "! python test.py --dataroot ./datasets/onepiece/A/ --name color_pix2pix --model colorization --netG unet_512 --load_size 512 --crop_size 512 --num_test 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize outputs to appropriate resolution\n",
    "\n",
    "result_dir = \"results/color_pix2pix/test_latest/images/\"\n",
    "\n",
    "img_list = os.listdir(result_dir)\n",
    "num_imgs = len(img_list)\n",
    "for n in range(num_imgs):\n",
    "    name_s = img_list[n]\n",
    "    path_s = os.path.join(result_dir, name_s)\n",
    "    im_s = cv2.imread(path_s, 1)\n",
    "    im_l = cv2.resize(im_s, (520,800), interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imwrite(path_s, im_l)\n",
    "    \n",
    "# The result is in html form stored in results/color_pix2pix/test_latest/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

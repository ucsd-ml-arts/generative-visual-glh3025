{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manga Colorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Black&White manga/comic colorization, based on pix2pix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequests: Python 3, GPU # This notebook was tested in datahub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ml-art-project4'...\n",
      "remote: Enumerating objects: 267, done.\u001b[K\n",
      "remote: Counting objects: 100% (267/267), done.\u001b[K\n",
      "remote: Compressing objects: 100% (256/256), done.\u001b[K\n",
      "remote: Total 267 (delta 6), reused 264 (delta 6), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (267/267), 37.49 MiB | 35.03 MiB/s, done.\n",
      "Resolving deltas: 100% (6/6), done.\n",
      "Checking out files: 100% (243/243), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/glh3025/ml-art-project4.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ml-art-project4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-30 14:51:47--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
      "Resolving web.ucsd.edu (web.ucsd.edu)... 132.239.1.230, 132.239.1.231\n",
      "Connecting to web.ucsd.edu (web.ucsd.edu)|132.239.1.230|:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 16648024 (16M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
      "\n",
      "ngrok-stable-linux- 100%[===================>]  15.88M  12.8MB/s    in 1.2s    \n",
      "\n",
      "2019-05-30 14:51:49 (12.8 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [16648024/16648024]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ngrok-stable-linux-amd64.zip\n",
      "  inflating: ngrok                   \n"
     ]
    }
   ],
   "source": [
    "! unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let Visdom run background, 8097 is the default output port of pix2pix model.\n",
    "get_ipython().system_raw('python3 -m visdom.server -port 8097 >> visdomlog.txt 2>&1 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 8097 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://0d7b8246.ngrok.io\r\n"
     ]
    }
   ],
   "source": [
    "# Click the link below to access Visdom.\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split = val, use 28/28 images\n",
      "split = val, number of images = 28\n",
      "split = test, use 8/8 images\n",
      "split = test, number of images = 8\n",
      "split = train, use 141/141 images\n",
      "split = train, number of images = 141\n"
     ]
    }
   ],
   "source": [
    "# Make B&W images from colored ones to save some time\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "data_dir_A = \"datasets/onepiece/A/\"\n",
    "data_dir_B = \"datasets/onepiece/B/\"\n",
    "data_dir_AB = \"datasets/onepiece_AB/\"\n",
    "\n",
    "splits = os.listdir(data_dir_A)\n",
    "\n",
    "for sp in splits:\n",
    "    img_fold_A = os.path.join(data_dir_A, sp)\n",
    "    img_fold_B = os.path.join(data_dir_B, sp)\n",
    "    if not os.path.isdir(img_fold_B):\n",
    "        os.makedirs(img_fold_B)\n",
    "    img_list = os.listdir(img_fold_A)\n",
    "    num_imgs = len(img_list)\n",
    "    print('split = %s, use %d/%d images' % (sp, num_imgs, len(img_list)))\n",
    "    img_fold_AB = os.path.join(data_dir_AB, sp)\n",
    "    if not os.path.isdir(img_fold_AB):\n",
    "        os.makedirs(img_fold_AB)\n",
    "    print('split = %s, number of images = %d' % (sp, num_imgs))\n",
    "    for n in range(num_imgs):\n",
    "        name_A = img_list[n]\n",
    "        path_A = os.path.join(img_fold_A, name_A)\n",
    "        name_B = name_A\n",
    "        path_B = os.path.join(img_fold_B, name_B)\n",
    "        \n",
    "        if os.path.isfile(path_A):# and os.path.isfile(path_B):\n",
    "            name_AB = name_A\n",
    "            path_AB = os.path.join(img_fold_AB, name_AB)\n",
    "            im_A = cv2.imread(path_A, 1) # python2: cv2.CV_LOAD_IMAGE_COLOR; python3: cv2.IMREAD_COLOR\n",
    "#             im_B = cv2.imread(path_B, 1) # python2: cv2.CV_LOAD_IMAGE_COLOR; python3: cv2.IMREAD_COLOR\n",
    "            im_B = cv2.cvtColor(im_A, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imwrite(path_B, im_B)\n",
    "#             im_AB = np.concatenate([im_A, im_B], 1)\n",
    "#             cv2.imwrite(path_AB, im_AB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 512                           \t[default: 256]\n",
      "                 dataroot: ./datasets/onepiece/A/        \t[default: None]\n",
      "             dataset_mode: colorization                  \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 568                           \t[default: 286]\n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: colorization                  \t[default: cycle_gan]\n",
      "               n_layers_D: 3                             \n",
      "                     name: color_pix2pix                 \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_512                      \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "                    niter: 100                           \n",
      "              niter_decay: 100                           \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 2                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [ColorizationDataset] was created\n",
      "The number of training images = 177\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [ColorizationModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 66.995 M\n",
      "[Network D] Total number of parameters : 2.766 M\n",
      "-----------------------------------------------\n",
      "WARNING:root:Setting up a new session...\n",
      "create web directory ./checkpoints/color_pix2pix/web...\n",
      "(epoch: 1, iters: 100, time: 0.104, data: 0.752) G_GAN: 1.677 G_L1: 12.467 D_real: 0.373 D_fake: 0.566 \n",
      "End of epoch 1 / 200 \t Time Taken: 24 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 23, time: 0.106, data: 0.002) G_GAN: 1.912 G_L1: 8.315 D_real: 0.707 D_fake: 0.318 \n",
      "(epoch: 2, iters: 123, time: 0.119, data: 0.000) G_GAN: 1.009 G_L1: 7.531 D_real: 0.227 D_fake: 1.158 \n",
      "End of epoch 2 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 46, time: 1.096, data: 0.003) G_GAN: 0.772 G_L1: 6.521 D_real: 1.433 D_fake: 0.415 \n",
      "(epoch: 3, iters: 146, time: 0.175, data: 0.004) G_GAN: 1.160 G_L1: 7.026 D_real: 0.259 D_fake: 0.662 \n",
      "End of epoch 3 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 69, time: 0.124, data: 0.003) G_GAN: 1.732 G_L1: 7.963 D_real: 0.190 D_fake: 0.416 \n",
      "(epoch: 4, iters: 169, time: 0.120, data: 0.003) G_GAN: 1.172 G_L1: 7.731 D_real: 0.645 D_fake: 0.756 \n",
      "End of epoch 4 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 16 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 5, iters: 92, time: 1.051, data: 0.003) G_GAN: 0.993 G_L1: 7.798 D_real: 0.567 D_fake: 0.410 \n",
      "saving the model at the end of epoch 5, iters 885\n",
      "End of epoch 5 / 200 \t Time Taken: 23 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 15, time: 0.118, data: 0.004) G_GAN: 1.039 G_L1: 8.765 D_real: 0.197 D_fake: 0.702 \n",
      "(epoch: 6, iters: 115, time: 0.165, data: 0.002) G_GAN: 0.757 G_L1: 10.256 D_real: 0.344 D_fake: 0.675 \n",
      "End of epoch 6 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 38, time: 0.172, data: 0.001) G_GAN: 1.172 G_L1: 4.372 D_real: 1.621 D_fake: 0.752 \n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 20 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 7, iters: 138, time: 1.230, data: 0.003) G_GAN: 1.556 G_L1: 7.600 D_real: 0.177 D_fake: 0.871 \n",
      "End of epoch 7 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 61, time: 0.122, data: 0.004) G_GAN: 1.196 G_L1: 7.359 D_real: 1.150 D_fake: 0.444 \n",
      "(epoch: 8, iters: 161, time: 0.155, data: 0.002) G_GAN: 1.456 G_L1: 9.884 D_real: 0.201 D_fake: 0.488 \n",
      "End of epoch 8 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 84, time: 0.152, data: 0.002) G_GAN: 0.901 G_L1: 5.394 D_real: 0.881 D_fake: 0.700 \n",
      "End of epoch 9 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 7, time: 1.140, data: 0.002) G_GAN: 1.301 G_L1: 8.097 D_real: 0.233 D_fake: 0.778 \n",
      "(epoch: 10, iters: 107, time: 0.175, data: 0.001) G_GAN: 0.885 G_L1: 6.747 D_real: 1.212 D_fake: 1.107 \n",
      "saving the model at the end of epoch 10, iters 1770\n",
      "End of epoch 10 / 200 \t Time Taken: 23 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 30, time: 0.119, data: 0.002) G_GAN: 1.021 G_L1: 6.206 D_real: 0.541 D_fake: 0.756 \n",
      "(epoch: 11, iters: 130, time: 0.157, data: 0.001) G_GAN: 1.107 G_L1: 7.760 D_real: 0.603 D_fake: 0.303 \n",
      "End of epoch 11 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 53, time: 1.151, data: 0.003) G_GAN: 2.343 G_L1: 6.604 D_real: 0.083 D_fake: 0.274 \n",
      "(epoch: 12, iters: 153, time: 0.118, data: 0.003) G_GAN: 1.422 G_L1: 9.769 D_real: 0.409 D_fake: 0.247 \n",
      "End of epoch 12 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 76, time: 0.117, data: 0.002) G_GAN: 1.020 G_L1: 6.924 D_real: 0.631 D_fake: 0.458 \n",
      "(epoch: 13, iters: 176, time: 0.079, data: 0.001) G_GAN: 0.949 G_L1: 9.080 D_real: 1.633 D_fake: 0.918 \n",
      "End of epoch 13 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 49 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 14, iters: 99, time: 1.191, data: 0.002) G_GAN: 0.646 G_L1: 6.544 D_real: 0.898 D_fake: 0.555 \n",
      "End of epoch 14 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 22, time: 0.118, data: 0.002) G_GAN: 1.377 G_L1: 6.059 D_real: 0.419 D_fake: 1.101 \n",
      "(epoch: 15, iters: 122, time: 0.164, data: 0.059) G_GAN: 1.330 G_L1: 6.480 D_real: 0.630 D_fake: 0.457 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model at the end of epoch 15, iters 2655\n",
      "End of epoch 15 / 200 \t Time Taken: 22 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 45, time: 0.172, data: 0.002) G_GAN: 0.903 G_L1: 5.018 D_real: 1.169 D_fake: 0.488 \n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 3 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 16, iters: 145, time: 1.078, data: 0.002) G_GAN: 2.060 G_L1: 11.354 D_real: 0.400 D_fake: 0.168 \n",
      "End of epoch 16 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 68, time: 0.113, data: 0.002) G_GAN: 1.195 G_L1: 7.202 D_real: 0.756 D_fake: 0.429 \n",
      "(epoch: 17, iters: 168, time: 0.123, data: 0.001) G_GAN: 1.098 G_L1: 6.515 D_real: 0.538 D_fake: 0.468 \n",
      "End of epoch 17 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 91, time: 0.119, data: 0.005) G_GAN: 1.229 G_L1: 7.396 D_real: 0.240 D_fake: 0.746 \n",
      "End of epoch 18 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 2 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 19, iters: 14, time: 1.106, data: 0.002) G_GAN: 1.544 G_L1: 7.310 D_real: 0.153 D_fake: 0.672 \n",
      "(epoch: 19, iters: 114, time: 0.113, data: 0.001) G_GAN: 1.191 G_L1: 5.663 D_real: 0.611 D_fake: 0.283 \n",
      "End of epoch 19 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 37, time: 0.102, data: 0.002) G_GAN: 1.646 G_L1: 11.368 D_real: 0.230 D_fake: 0.533 \n",
      "(epoch: 20, iters: 137, time: 0.175, data: 0.002) G_GAN: 1.102 G_L1: 5.484 D_real: 0.810 D_fake: 0.425 \n",
      "saving the model at the end of epoch 20, iters 3540\n",
      "End of epoch 20 / 200 \t Time Taken: 22 sec\n",
      "learning rate = 0.0002000\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 10 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 21, iters: 60, time: 1.208, data: 0.003) G_GAN: 1.514 G_L1: 7.199 D_real: 0.484 D_fake: 0.288 \n",
      "(epoch: 21, iters: 160, time: 0.114, data: 0.003) G_GAN: 1.503 G_L1: 8.577 D_real: 0.099 D_fake: 0.680 \n",
      "End of epoch 21 / 200 \t Time Taken: 22 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 83, time: 0.122, data: 0.002) G_GAN: 1.437 G_L1: 6.139 D_real: 0.273 D_fake: 0.344 \n",
      "End of epoch 22 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 6, time: 0.185, data: 0.003) G_GAN: 0.932 G_L1: 5.107 D_real: 1.693 D_fake: 0.216 \n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 9 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 23, iters: 106, time: 1.185, data: 0.003) G_GAN: 1.034 G_L1: 7.480 D_real: 0.425 D_fake: 0.719 \n",
      "End of epoch 23 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 29, time: 0.184, data: 0.003) G_GAN: 1.832 G_L1: 7.739 D_real: 0.509 D_fake: 0.246 \n",
      "(epoch: 24, iters: 129, time: 0.123, data: 0.004) G_GAN: 1.296 G_L1: 9.017 D_real: 0.266 D_fake: 0.447 \n",
      "End of epoch 24 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 52, time: 0.181, data: 0.002) G_GAN: 1.346 G_L1: 9.012 D_real: 0.147 D_fake: 0.528 \n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 189 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 25, iters: 152, time: 1.079, data: 0.002) G_GAN: 1.228 G_L1: 3.769 D_real: 1.550 D_fake: 0.246 \n",
      "saving the model at the end of epoch 25, iters 4425\n",
      "End of epoch 25 / 200 \t Time Taken: 22 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 75, time: 0.098, data: 0.003) G_GAN: 0.628 G_L1: 9.706 D_real: 0.729 D_fake: 0.607 \n",
      "(epoch: 26, iters: 175, time: 0.082, data: 0.003) G_GAN: 1.294 G_L1: 6.915 D_real: 0.661 D_fake: 0.583 \n",
      "End of epoch 26 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 98, time: 0.130, data: 0.002) G_GAN: 0.742 G_L1: 6.851 D_real: 1.672 D_fake: 0.444 \n",
      "End of epoch 27 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 21, time: 1.182, data: 0.002) G_GAN: 0.863 G_L1: 4.801 D_real: 1.110 D_fake: 0.300 \n",
      "(epoch: 28, iters: 121, time: 0.122, data: 0.004) G_GAN: 1.001 G_L1: 6.262 D_real: 0.175 D_fake: 0.684 \n",
      "End of epoch 28 / 200 \t Time Taken: 22 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 44, time: 0.155, data: 0.004) G_GAN: 0.937 G_L1: 5.720 D_real: 1.084 D_fake: 0.328 \n",
      "saving the latest model (epoch 29, total_iters 5000)\n",
      "(epoch: 29, iters: 144, time: 0.123, data: 0.003) G_GAN: 1.505 G_L1: 5.841 D_real: 0.139 D_fake: 0.532 \n",
      "End of epoch 29 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 5 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "(epoch: 30, iters: 67, time: 1.034, data: 0.002) G_GAN: 1.749 G_L1: 4.021 D_real: 0.453 D_fake: 0.552 \n",
      "(epoch: 30, iters: 167, time: 0.120, data: 0.004) G_GAN: 1.175 G_L1: 5.428 D_real: 0.504 D_fake: 0.577 \n",
      "saving the model at the end of epoch 30, iters 5310\n",
      "End of epoch 30 / 200 \t Time Taken: 23 sec\n",
      "learning rate = 0.0002000\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 50, in <module>\n",
      "    model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
      "  File \"/datasets/home/home-03/75/075/lgong/ml-art-project4/models/pix2pix_model.py\", line 82, in set_input\n",
      "    self.real_A = input['A' if AtoB else 'B'].to(self.device)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Train model using ~150 onepiece pages. More pages will be better.\n",
    "# modified generator model to Unet512 to get higher resolution image.\n",
    "# By default will train 200 epochs, but ~20 epochs is enough for me.\n",
    "! python train.py --dataroot ./datasets/onepiece/A/ --name color_pix2pix --model colorization --netG unet_512 --load_size 568 --crop_size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 512                           \t[default: 256]\n",
      "                 dataroot: ./datasets/onepiece/A/        \t[default: None]\n",
      "             dataset_mode: colorization                  \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 1                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 512                           \t[default: 256]\n",
      "         max_dataset_size: inf                           \n",
      "                    model: colorization                  \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: color_pix2pix                 \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_512                      \t[default: unet_256]\n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                    ntest: inf                           \n",
      "                 num_test: 8                             \t[default: 50]\n",
      "              num_threads: 4                             \n",
      "                output_nc: 2                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [ColorizationDataset] was created\n",
      "initialize network with normal\n",
      "model [ColorizationModel] was created\n",
      "loading the model from ./checkpoints/color_pix2pix/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 66.995 M\n",
      "-----------------------------------------------\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 6 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "processing (0000)-th image... ['./datasets/onepiece/A/test/0001-011.png.jpeg']\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 22 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 19 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 34 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 51 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 56 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "processing (0005)-th image... ['./datasets/onepiece/A/test/0005-011.png.jpeg']\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 16 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/color/colorconv.py:993: UserWarning: Color data out of range: Z < 0 in 29 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    }
   ],
   "source": [
    "# Generate colored pages from B&W testset.\n",
    "! python test.py --dataroot ./datasets/onepiece/A/ --name color_pix2pix --model colorization --netG unet_512 --load_size 512 --crop_size 512 --num_test 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize outputs to appropriate resolution\n",
    "\n",
    "result_dir = \"results/color_pix2pix/test_latest/images/\"\n",
    "\n",
    "img_list = os.listdir(result_dir)\n",
    "num_imgs = len(img_list)\n",
    "for n in range(num_imgs):\n",
    "    name_s = img_list[n]\n",
    "    path_s = os.path.join(result_dir, name_s)\n",
    "    im_s = cv2.imread(path_s, 1)\n",
    "    im_l = cv2.resize(im_s, (520,800), interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imwrite(path_s, im_l)\n",
    "    \n",
    "# The result is in html form stored in results/color_pix2pix/test_latest/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

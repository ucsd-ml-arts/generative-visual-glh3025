# Project 4 Generative Visual

Lihang Gong, lgong@ucsd.edu

## Abstract

As a manga/comic reader, I would be more pleasure to read colorized ones than gray-scaled ones. However, it spends much additional time for comic book creators to paint from the black&white version. What if we have an auto painter that convert b&w manga into colorized ones? In this project, I developed a manga colorization solution based on pix2pix model. It is able to colorize b&w manga pages based on some colorized samples. The future direction is to correct some inaccurate results and make them more natural.


## Model/Data

- trained models
- training data (or link to training data)

## Code

run thi to simply regenerate the demonstrated results.
- Python: generative_code.py
- Jupyter notebooks: generative_code.ipynb

## Results

Documentation of your results in an appropriate format, both links to files and a brief description of their contents:
- image files (`.jpg`, `.png` or whatever else is appropriate)
- move files (uploaded to youtube or vimeo due to github file size limits)
- ... some other form

## Technical Notes

- Draw codes either from this repository or from https://github.com/glh3025/ml-art-project4
- Tested on Datahub.

## Reference

- [pix2pix paper](https://arxiv.org/pdf/1611.07004.pdf)
- [Pytorch implementation of pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)

